{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import random\n",
    "import sys,os\n",
    "import time,datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeStampToDate(ts):\n",
    "    timeStamp = ts\n",
    "    timeArray = time.localtime(timeStamp)\n",
    "    otherStyleTime = time.strftime(\"%Y--%m--%d %H:%M:%S\", timeArray)\n",
    "    year = int(time.strftime(\"%Y\",timeArray))\n",
    "    month = int(time.strftime(\"%m\",timeArray))\n",
    "    date = int(time.strftime(\"%d\",timeArray))\n",
    "    day = datetime.datetime(year,month,date).strftime(\"%w\")\n",
    "    \n",
    "    return month,date,day\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(percentage):\n",
    "    #打开训练集\n",
    "    with open('train.csv') as trainDataFile:\n",
    "        trainData = []\n",
    "        trainLabel = []\n",
    "        #第一行为表头，不需要，去掉\n",
    "        next(trainDataFile)\n",
    "        print('Loading data.....')\n",
    "        #用于记录数据集大小\n",
    "        count = 0\n",
    "        for line in trainDataFile:\n",
    "            #每读入100w数据的时候提示\n",
    "            if count%1000000 == 0:\n",
    "                print('Loading the '+ str(count) + ' data')\n",
    "            count = count + 1\n",
    "            \n",
    "            #去掉每一行的换行符，并且分割字符串形成数组\n",
    "            line = line.strip('\\n')\n",
    "            tmp = line.split(',')\n",
    "            #用于存储每一行量化后的数据\n",
    "            tmp_real = []\n",
    "            #记录列数，对不同列进行不同操作\n",
    "            column_num = 1\n",
    "            #保存时间戳返回的月，日，星期几\n",
    "            day = 0\n",
    "            date = 0\n",
    "            month = 0\n",
    "            #量化每一行数据\n",
    "            for item in tmp:\n",
    "                #第一列行号ID不需要，去掉\n",
    "                if column_num == 1:\n",
    "                    column_num = column_num + 1\n",
    "                    continue\n",
    "                #第五列时间戳进行转化\n",
    "                elif column_num == 5:\n",
    "                    #通过时间戳计算月，日，星期几\n",
    "                    month,date,day = timeStampToDate(int(item))\n",
    "                    tmp_real.append(float(month))\n",
    "                    tmp_real.append(float(date))\n",
    "                    tmp_real.append(float(day))\n",
    "                    column_num = column_num + 1\n",
    "                    continue\n",
    "                tmp_real.append(float(item))\n",
    "                column_num = column_num + 1\n",
    "            #将量化后的数据行插入到总数据集中\n",
    "            trainData.append(tmp_real[:-1])\n",
    "            #插入标签\n",
    "            trainLabel.append(int(tmp_real[-1]))\n",
    "        #太多的数据难以训练，使用一定的比例的训练集\n",
    "        trainData = trainData[:int(len(trainData)*percentage)]\n",
    "        #测试集与训练集比例为1:3\n",
    "        testLen = len(trainData)/4\n",
    "        trainLen = len(trainData) - testLen\n",
    "        print('Data Successfully loaded' + 'We use ' + str(percentage) +'% of the total data....')\n",
    "        #形成训练集和测试集合\n",
    "        testData_X = []\n",
    "        testData_Y = []\n",
    "                             \n",
    "        print('Dealing with ' + str(int(len(trainData)*percentage)) + ' data')\n",
    "        print()\n",
    "        #每次训练随机抽取训练集和测试集，交叉验证，可是数据集过大，操作速度太慢，注释\n",
    "#         count = 0\n",
    "#         for i in range(0,testLen):\n",
    "#             #sys.stdout.write('Dealing with the '+ str(i) + ' data')\n",
    "#             if count%500 == 0:\n",
    "#                 print('Dealing with the '+ str(i) + ' data')\n",
    "#             count = count + 1\n",
    "#             #sys.stdout.flush()                 \n",
    "#             listIndex = random.randint(0,len(trainData)-1)\n",
    "#             testData_X.append(trainData[listIndex])\n",
    "#             trainData.remove(trainData[listIndex])\n",
    "#             testData_Y.append(trainLabel[listIndex])\n",
    "#             trainLabel.remove(trainLabel[listIndex])\n",
    "#         trainData_X = trainData\n",
    "#         trainData_Y = trainLabel\n",
    "\n",
    "        #形成训练集和测试集X为输入，Y为对应输出\n",
    "        trainData_X = trainData[:trainLen]\n",
    "        trainData_Y = trainLabel[:trainLen]\n",
    "        testData_X = trainData[trainLen:]\n",
    "        testData_Y = trainLabel[trainLen:]\n",
    "        \n",
    "        print('Data operated successfully !')\n",
    "        return trainData_X,trainData_Y,testData_X,testData_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data.....\n",
      "Loading the 0 data\n",
      "Loading the 1000000 data\n",
      "Loading the 2000000 data\n",
      "Loading the 3000000 data\n",
      "Loading the 4000000 data\n",
      "Loading the 5000000 data\n",
      "Loading the 6000000 data\n",
      "Loading the 7000000 data\n",
      "Loading the 8000000 data\n",
      "Loading the 9000000 data\n",
      "Loading the 10000000 data\n",
      "Loading the 11000000 data\n",
      "Loading the 12000000 data\n",
      "Loading the 13000000 data\n",
      "Loading the 14000000 data\n",
      "Loading the 15000000 data\n",
      "Loading the 16000000 data\n",
      "Loading the 17000000 data\n",
      "Loading the 18000000 data\n",
      "Loading the 19000000 data\n",
      "Loading the 20000000 data\n",
      "Loading the 21000000 data\n",
      "Loading the 22000000 data\n",
      "Loading the 23000000 data\n",
      "Loading the 24000000 data\n",
      "Loading the 25000000 data\n",
      "Loading the 26000000 data\n",
      "Loading the 27000000 data\n",
      "Loading the 28000000 data\n",
      "Loading the 29000000 data\n",
      "Data Successfully loadedWe use 0.1% of the total data....\n",
      "Dealing with 2911802 data\n",
      "()\n",
      "Data operated successfully !\n",
      "Starting KNN training process....\n",
      "Precison of training data: 0.36598038694929874\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [26934169, 727950]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-957527cde4eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-957527cde4eb>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainData_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precison of training data: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainData_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Precision of testing data: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestData_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction of the location : '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\software_real\\python\\lib\\site-packages\\sklearn\\base.pyc\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \"\"\"\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\software_real\\python\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\software_real\\python\\lib\\site-packages\\sklearn\\metrics\\classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\software_real\\python\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [26934169, 727950]"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #读取数据集\n",
    "    trainData_X,trainData_Y,testData_X,testData_Y = loadData(0.1)\n",
    "    #搭建KNN模型\n",
    "    knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "    #使用训练集训练模型\n",
    "    print('Starting KNN training process....')\n",
    "    knn.fit(trainData_X,trainData_Y)\n",
    "    print('Precison of training data: ' + str(knn.score(trainData_X,trainData_Y)))\n",
    "    print('Precision of testing data: ' + str(knn.score(testData_X,testData_Y)))\n",
    "    print('Prediction of the location : ')\n",
    "    print(knn.predict(testData_X))\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
